{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    416\n",
      "0    167\n",
      "Name: Liver_patients, dtype: int64\n",
      "167\n",
      "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   9,  10,\n",
      "            ...\n",
      "            571, 572, 573, 574, 575, 576, 577, 579, 580, 581],\n",
      "           dtype='int64', length=416)\n",
      "167\n",
      "Int64Index([  8,  12,  15,  17,  24,  28,  29,  32,  33,  34,\n",
      "            ...\n",
      "            539, 540, 541, 542, 545, 551, 564, 566, 578, 582],\n",
      "           dtype='int64', length=167)\n",
      "1    167\n",
      "0    167\n",
      "Name: Liver_patients, dtype: int64\n",
      "accuracy =  67.16417910447761 %\n",
      "Random Forest Score:  99.25\n",
      "Random Forest Test Score:  67.16\n",
      "Accuracy:  0.6716417910447762\n",
      "\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.69        33\n",
      "           1       0.71      0.59      0.65        34\n",
      "\n",
      "   micro avg       0.67      0.67      0.67        67\n",
      "   macro avg       0.68      0.67      0.67        67\n",
      "weighted avg       0.68      0.67      0.67        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report ,confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Import the datasets\n",
    "liverCSV = pd.read_csv('E:\\\\Thesis\\\\Indian_Liver_Patient.csv')\n",
    "# Handling the missing values\n",
    "df = pd.DataFrame(liverCSV)\n",
    "dataset = df.fillna(method='ffill', axis = 0)\n",
    "\n",
    "# process  of checking the missing columns values\n",
    "dataset.columns[dataset.isnull().any()]\n",
    "\n",
    "\n",
    "# start oversampling process\n",
    "\n",
    "target = 'Liver_patients'\n",
    "\n",
    "# dataset counts 1 or 0 \n",
    "print(dataset[target].value_counts())\n",
    "\n",
    "# minority class length i.e 1\n",
    "minority_class_len = len(dataset[dataset[target] == 0])\n",
    "print(minority_class_len)\n",
    "\n",
    "# display the indices of majority class i.e 0\n",
    "majority_class_indices = dataset[dataset[target] == 1].index\n",
    "print(majority_class_indices)\n",
    "\n",
    "# randomly picking up the majority class indicies i.e. 0 \n",
    "random_majority_indices = np.random.choice(majority_class_indices, minority_class_len, replace=False)\n",
    "print(len(random_majority_indices))\n",
    "\n",
    "# displaing the minority class indices i.e. 1\n",
    "minority_class_indices = dataset[dataset[target] == 0].index\n",
    "print(minority_class_indices)\n",
    "\n",
    "# concatenate the minority indices and random majority incices\n",
    "under_sample_indices = np.concatenate([minority_class_indices, random_majority_indices])\n",
    "\n",
    "# locate the under_sample_indices to datasets\n",
    "under_sample = dataset.loc[under_sample_indices]\n",
    "\n",
    "# Bar Garph\n",
    "sns.countplot(x=target, data=under_sample)\n",
    "\n",
    "# displaing the values of 0 and 1\n",
    "print(under_sample[target].value_counts())\n",
    "\n",
    "# end oversampling process\n",
    "\n",
    "\n",
    "tData = np.asarray(under_sample.drop('Liver_patients', 1))\n",
    "tTarget = np.asarray(under_sample['Liver_patients'])\n",
    "\n",
    "# Normalize Data\n",
    "means = np.mean(tData, axis=0)\n",
    "stds = np.std(tData, axis=0)\n",
    "tData = (tData - means)/stds\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tData,tTarget,test_size=0.20)\n",
    "\n",
    "#applying Kernel PCA\n",
    "#from sklearn.decomposition import KernelPCA\n",
    "#kpca = KernelPCA(n_components = 3, kernel = 'rbf')\n",
    "#X_train = kpca.fit_transform(X_train)\n",
    "#X_test = kpca.transform(X_test)\n",
    "\n",
    "#create a random forest classifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_predicted = rf.predict(X_test)\n",
    "\n",
    "accuracy = rf.score(X_test, y_test)\n",
    "\n",
    "print(\"accuracy = \", accuracy * 100, \"%\")\n",
    "\n",
    "random_forest_score      = round(rf.score(X_train, y_train) * 100, 2)\n",
    "random_forest_score_test = round(rf.score(X_test, y_test) * 100, 2)\n",
    "\n",
    "print('Random Forest Score: ', random_forest_score)\n",
    "print('Random Forest Test Score: ', random_forest_score_test)\n",
    "print('Accuracy: ', accuracy_score(y_test,rf_predicted))\n",
    "print('\\nClassification report: \\n', classification_report(y_test,rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
