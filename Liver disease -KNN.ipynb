{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    416\n",
      "0    167\n",
      "Name: Liver_patients, dtype: int64\n",
      "167\n",
      "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   9,  10,\n",
      "            ...\n",
      "            571, 572, 573, 574, 575, 576, 577, 579, 580, 581],\n",
      "           dtype='int64', length=416)\n",
      "167\n",
      "Int64Index([  8,  12,  15,  17,  24,  28,  29,  32,  33,  34,\n",
      "            ...\n",
      "            539, 540, 541, 542, 545, 551, 564, 566, 578, 582],\n",
      "           dtype='int64', length=167)\n",
      "1    167\n",
      "0    167\n",
      "Name: Liver_patients, dtype: int64\n",
      "accuracy =  74.6268656716418 %\n",
      "[[29  9]\n",
      " [ 8 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77        38\n",
      "           1       0.70      0.72      0.71        29\n",
      "\n",
      "   micro avg       0.75      0.75      0.75        67\n",
      "   macro avg       0.74      0.74      0.74        67\n",
      "weighted avg       0.75      0.75      0.75        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import the datasets\n",
    "liverCSV = pd.read_csv('E:\\\\Thesis\\\\Indian_Liver_Patient.csv')\n",
    "\n",
    "# Handling the missing values\n",
    "df = pd.DataFrame(liverCSV)\n",
    "dataset = df.fillna(method='ffill', axis = 0)\n",
    "\n",
    "# process  of checking the missing columns values\n",
    "dataset.columns[dataset.isnull().any()]\n",
    "\n",
    "\n",
    "# start oversampling process\n",
    "\n",
    "target = 'Liver_patients'\n",
    "\n",
    "# dataset counts 1 or 0 \n",
    "print(dataset[target].value_counts())\n",
    "\n",
    "# minority class length i.e 1\n",
    "minority_class_len = len(dataset[dataset[target] == 0])\n",
    "print(minority_class_len)\n",
    "\n",
    "# display the indices of majority class i.e 0\n",
    "majority_class_indices = dataset[dataset[target] == 1].index\n",
    "print(majority_class_indices)\n",
    "\n",
    "# randomly picking up the majority class indicies i.e. 0 \n",
    "random_majority_indices = np.random.choice(majority_class_indices, minority_class_len, replace=False)\n",
    "print(len(random_majority_indices))\n",
    "\n",
    "# displaing the minority class indices i.e. 1\n",
    "minority_class_indices = dataset[dataset[target] == 0].index\n",
    "print(minority_class_indices)\n",
    "\n",
    "# concatenate the minority indices and random majority incices\n",
    "under_sample_indices = np.concatenate([minority_class_indices, random_majority_indices])\n",
    "\n",
    "# locate the under_sample_indices to datasets\n",
    "under_sample = dataset.loc[under_sample_indices]\n",
    "\n",
    "# Bar Garph\n",
    "sns.countplot(x=target, data=under_sample)\n",
    "\n",
    "# displaing the values of 0 and 1\n",
    "print(under_sample[target].value_counts())\n",
    "\n",
    "# end oversampling process\n",
    "\n",
    "\n",
    "tData = np.asarray(under_sample.drop('Liver_patients', 1))\n",
    "tTarget = np.asarray(under_sample['Liver_patients'])\n",
    "\n",
    "# Normalize Data\n",
    "means = np.mean(tData, axis=0)\n",
    "stds = np.std(tData, axis=0)\n",
    "tData = (tData - means)/stds\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tData,tTarget,test_size=0.20)\n",
    "\n",
    "#applying Kernel PCA\n",
    "#from sklearn.decomposition import KernelPCA\n",
    "#kpca = KernelPCA(n_components = 3, kernel = 'rbf')\n",
    "#X_train = kpca.fit_transform(X_train)\n",
    "#X_test = kpca.transform(X_test) \n",
    "\n",
    "\n",
    "\n",
    "#create KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#training the model\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#check performance using accurcay\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "\n",
    "print(\"accuracy = \", accuracy * 100, \"%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred = knn.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
